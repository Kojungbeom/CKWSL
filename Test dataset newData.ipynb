{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Val Result: Acc: 0.7497, C_ACC: 0.9430, DOA: 12.5635, ACC_k: 0.8972\n",
      "28\n",
      "Val Result: Acc: 0.7488, C_ACC: 0.9451, DOA: 12.3970, ACC_k: 0.8986\n",
      "29\n",
      "Val Result: Acc: 0.7487, C_ACC: 0.9435, DOA: 12.5144, ACC_k: 0.8978\n",
      "30\n",
      "Val Result: Acc: 0.7472, C_ACC: 0.9442, DOA: 12.6404, ACC_k: 0.8958\n",
      "31\n",
      "Val Result: Acc: 0.7493, C_ACC: 0.9430, DOA: 12.5172, ACC_k: 0.8978\n",
      "32\n",
      "Val Result: Acc: 0.7510, C_ACC: 0.9447, DOA: 12.3919, ACC_k: 0.9002\n",
      "33\n",
      "Val Result: Acc: 0.7477, C_ACC: 0.9440, DOA: 12.5627, ACC_k: 0.8956\n",
      "34\n",
      "Val Result: Acc: 0.7497, C_ACC: 0.9440, DOA: 12.4957, ACC_k: 0.8998\n",
      "35\n",
      "Val Result: Acc: 0.7503, C_ACC: 0.9435, DOA: 12.3818, ACC_k: 0.9006\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.utils_base as uBase\n",
    "from models.KSL_EFFI_v3 import EfficientNet\n",
    "from dataset_MT_KWS import MC_MT_KWS_Dataset, Overlap_interference\n",
    "from IPython.display import Audio\n",
    "from dataset_MT_newData import new_Dataset\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "encoder_ch = [[6,64],[64,128],[128,256],[256,256]]\n",
    "net = EfficientNet().cuda()\n",
    "learning_rate = 0.0005\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[14,18,23], gamma=0.1)\n",
    "\n",
    "coarse_loss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "fine_loss = nn.MSELoss(reduction=\"sum\")\n",
    "cls_loss = nn.BCELoss(reduction=\"sum\")\n",
    "ext_loss = nn.L1Loss(reduction=\"sum\")\n",
    "b = 0\n",
    "\n",
    "annotation = \"newData3.csv\"\n",
    "\n",
    "train_annotation = 'newData3_train.csv'\n",
    "valid_annotation = 'newData3_valid.csv'\n",
    "test_annotation = 'newData3_test.csv'\n",
    "\n",
    "train_dataset = new_Dataset(annotations_file=train_annotation)\n",
    "valid_dataset = new_Dataset(annotations_file=valid_annotation)\n",
    "test_dataset = new_Dataset(annotations_file=test_annotation)\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size)\n",
    "valid_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=10)\n",
    "\n",
    "for i in range(27, 36):\n",
    "    net = EfficientNet().cuda()\n",
    "    print(i)\n",
    "    path = \"weight/20230530-133newData/\" + str(i) + \".pt\"\n",
    "    net.load_state_dict(torch.load(path))\n",
    "\n",
    "    net.eval()\n",
    "    accuracy = 0.0\n",
    "    loss = 0\n",
    "    CoarW = 0. \n",
    "    FineW = 0.\n",
    "    ExtW = 0.\n",
    "    ClsW = 1.\n",
    "    b1 = 0\n",
    "    predicts = []\n",
    "    gts = []\n",
    "\n",
    "    coeff_total = CoarW + FineW + ExtW + ClsW\n",
    "    CoarW = CoarW / coeff_total\n",
    "    FineW = FineW / coeff_total\n",
    "    ExtW = ExtW / coeff_total\n",
    "    ClsW = ClsW / coeff_total\n",
    "    class_acc = 0.0\n",
    "    doa_err = 0.0\n",
    "    doa_acc = 0.0\n",
    "    count = 0.0\n",
    "    tloss_ext = 0.\n",
    "    tloss_cls = 0.\n",
    "    tloss_coar = 0.\n",
    "    tloss_fine = 0.\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch_index, (x_sg, y_region, y_angle, y_class, bce, _) in enumerate(valid_dataloader):\n",
    "        x_sg = x_sg.cuda()\n",
    "        y_region = y_region.cuda()\n",
    "        y_angle = y_angle.cuda()\n",
    "        y_class = y_class.cuda()\n",
    "        bce = bce.cuda()\n",
    "\n",
    "        out_localizer1, out_localizer2, out_detector = net(x_sg)\n",
    "\n",
    "        #loss_ext = ext_loss(y_class.unsqueeze(1).unsqueeze(1) * torch.tanh(out_extractor), y_sg)\n",
    "        loss_cls = cls_loss(torch.sigmoid(out_detector), y_class.unsqueeze(1))\n",
    "        loss_coarse = coarse_loss(y_class.unsqueeze(1) * out_localizer1, (y_class * y_region).long())\n",
    "        loss_fine = fine_loss(y_class.unsqueeze(1) * bce * torch.sigmoid(out_localizer2), y_class.unsqueeze(1) * y_angle)\n",
    "\n",
    "        #tloss_ext += loss_ext.item()\n",
    "        tloss_cls += loss_cls.item()\n",
    "        tloss_coar += loss_coarse.item()\n",
    "        tloss_fine += loss_fine.item()\n",
    "\n",
    "        loss = ClsW * loss_cls + \\\n",
    "            CoarW * loss_coarse + \\\n",
    "            FineW * loss_fine \n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, region_pidx = out_localizer1.max(1)\n",
    "        accuracy += region_pidx.eq(y_region).sum()\n",
    "\n",
    "        class_acc += (torch.sigmoid(out_detector) > 0.5).squeeze(1).eq(y_class).sum()\n",
    "        a, b, c = uBase.DOA(y_region, y_angle, out_localizer1, out_localizer2, 20, y_class, torch.sigmoid(out_detector))\n",
    "\n",
    "        doa_err += a\n",
    "        doa_acc += b\n",
    "        count += c\n",
    "        predicts.append(torch.sigmoid(out_detector).detach().cpu()[0])\n",
    "        gts.append(y_class.detach().cpu())\n",
    "    print('Val Result: Acc: {:0.4f}, C_ACC: {:0.4f}, DOA: {:0.4f}, ACC_k: {:0.4f}'.format(\n",
    "            accuracy.float() / (len(test_dataset)),\n",
    "            class_acc.float() / (len(test_dataset)),\n",
    "            doa_err / count,\n",
    "            doa_acc / count\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.86, recall: 0.9221035982601818, precision: 0.954954954954955\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0.5]:\n",
    "    predict2 = []\n",
    "    gt2 = []\n",
    "    for i, j in enumerate(predicts):\n",
    "        predict2.append(float(j[0]))\n",
    "        gt2.append(float(gts[i]))\n",
    "\n",
    "    predict2 = np.array(predict2)\n",
    "    gt2 = np.array(gt2)\n",
    "\n",
    "    predict2[predict2 > 0.5] = 1\n",
    "    predict2[predict2 <= 0.5] = 0\n",
    "    gt2[gt2==0] = 0\n",
    "\n",
    "\n",
    "    confusion_dictionary = {'TP':0, 'TN':0, 'FP':0, 'FN':0}\n",
    "    for i in range(len(predict2)):\n",
    "        #print(predict2[i], gt2[i])\n",
    "        if predict2[i] and gt2[i]:\n",
    "            confusion_dictionary['TP'] += 1\n",
    "        elif not predict2[i] and not gt2[i]:\n",
    "            confusion_dictionary['TN'] += 1\n",
    "        elif predict2[i] and not gt2[i]:\n",
    "            confusion_dictionary['FP'] += 1\n",
    "        elif not predict2[i] and gt2[i]:\n",
    "            confusion_dictionary['FN'] += 1\n",
    "\n",
    "    predict2 = predict2 > 0.3\n",
    "    correct = sum(predict2 == gt2)\n",
    "    accuracy = correct / len(gt2)\n",
    "    recall = confusion_dictionary['TP'] / (confusion_dictionary['TP'] + confusion_dictionary['FN'])\n",
    "    precision = confusion_dictionary['TP'] / (confusion_dictionary['TP'] + confusion_dictionary['FP'])\n",
    "    print(f'accuracy: {accuracy*100}, recall: {recall}, precision: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/8\n",
    "35: C_ACC: 0.9482, DOA: 15.3921, ACC_k: 0.8675\n",
    "34: C_ACC: 0.9475, DOA: 15.5010, ACC_k: 0.8681\n",
    "33: C_ACC: 0.9484, DOA: 15.4654, ACC_k: 0.8667\n",
    "32: C_ACC: 0.9488, DOA: 15.5006, ACC_k: 0.8681\n",
    "31: C_ACC: 0.9487, DOA: 15.4353, ACC_k: 0.8689\n",
    "30: C_ACC: 0.9499, DOA: 15.3966, ACC_k: 0.8673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3/7\n",
    "35: C_ACC: 0.9479, DOA: 14.4433, ACC_k: 0.8780\n",
    "34: C_ACC: 0.9468, DOA: 14.5302, ACC_k: 0.8774\n",
    "33: C_ACC: 0.9471, DOA: 14.3725, ACC_k: 0.8774\n",
    "32: C_ACC: 0.9456, DOA: 14.3308, ACC_k: 0.8796\n",
    "31: C_ACC: 0.9470, DOA: 14.5621, ACC_k: 0.8764\n",
    "30: C_ACC: 0.9468, DOA: 14.6805, ACC_k: 0.8749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4/6\n",
    "35: C_ACC: 0.9448, DOA: 13.9235, ACC_k: 0.8808\n",
    "34: C_ACC: 0.9449, DOA: 13.8223, ACC_k: 0.8810\n",
    "33: C_ACC: 0.9452, DOA: 13.8171, ACC_k: 0.8820\n",
    "32: C_ACC: 0.9441, DOA: 13.9488, ACC_k: 0.8812\n",
    "31: C_ACC: 0.9453, DOA: 14.0688, ACC_k: 0.8808\n",
    "30: C_ACC: 0.9450, DOA: 13.9199, ACC_k: 0.8832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5/5\n",
    "35: C_ACC: 0.9441, DOA: 13.2147, ACC_k: 0.8911\n",
    "34: C_ACC: 0.9440, DOA: 13.2691, ACC_k: 0.8889\n",
    "33: C_ACC: 0.9440, DOA: 13.2918, ACC_k: 0.8891\n",
    "32: C_ACC: 0.9448, DOA: 13.4858, ACC_k: 0.8881\n",
    "31: C_ACC: 0.9435, DOA: 13.2985, ACC_k: 0.8883\n",
    "30: C_ACC: 0.9445, DOA: 13.2183, ACC_k: 0.8911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6/4\n",
    "35: C_ACC: 0.9445, DOA: 13.1932, ACC_k: 0.8899\n",
    "34: C_ACC: 0.9444, DOA: 13.0334, ACC_k: 0.8915\n",
    "33: C_ACC: 0.9445, DOA: 13.1024, ACC_k: 0.8924\n",
    "32: C_ACC: 0.9440, DOA: 13.1143, ACC_k: 0.8903\n",
    "31: C_ACC: 0.9452, DOA: 13.1621, ACC_k: 0.8924\n",
    "30: C_ACC: 0.9444, DOA: 13.2463, ACC_k: 0.8893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7/3\n",
    "35:\n",
    "34:\n",
    "33:\n",
    "32:\n",
    "31:\n",
    "30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8/2\n",
    "35: C_ACC: 0.9413, DOA: 12.3727, ACC_k: 0.8954\n",
    "34: C_ACC: 0.9409, DOA: 12.5223, ACC_k: 0.8956\n",
    "33: C_ACC: 0.9410, DOA: 12.5815, ACC_k: 0.8934\n",
    "32: C_ACC: 0.9403, DOA: 12.3944, ACC_k: 0.8948\n",
    "31: C_ACC: 0.9404, DOA: 12.5520, ACC_k: 0.8944\n",
    "30: C_ACC: 0.9401, DOA: 12.6457, ACC_k: 0.8926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Result: Acc: 0.1650, C_ACC: 0.9760, DOA: 89.7939, ACC_k: 0.1164\n"
     ]
    }
   ],
   "source": [
    "print('Val Result: Acc: {:0.4f}, C_ACC: {:0.4f}, DOA: {:0.4f}, ACC_k: {:0.4f}'.format(\n",
    "        accuracy.float() / (len(train_dataset)),\n",
    "        class_acc.float() / (len(train_dataset)),\n",
    "        doa_err / count,\n",
    "        doa_acc / count\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6892, 1: 5282, 2: 6246, 3: 6444, 4: 4343, 5: 7123}\n"
     ]
    }
   ],
   "source": [
    "dic = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}\n",
    "for batch_index, (x_sg, y_sg, y_region, y_angle, y_class, bce, _) in enumerate(train_dataloader):\n",
    "    #print(y_class, y_region)\n",
    "    for yc, yr in zip(y_class, y_region):\n",
    "        if yc == 1:\n",
    "            dic[yr.item()] += 1\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGS-15: Val Result: Acc: 0.1558, C_ACC: 0.8310, DOA: 93.5251, ACC_k: 0.0997\n",
    "SGL-14: Val Result: Acc: 0.9217, C_ACC: 0.4947, DOA: 8.4955, ACC_k: 0.9548\n",
    "MT-12: Val Result: Acc: 0.8600, C_ACC: 0.8018, DOA: 10.1661, ACC_k: 0.9251\n",
    "MT-13: Val Result: Acc: 0.8675, C_ACC: 0.8052, DOA: 9.1426, ACC_k: 0.9342\n",
    "MT-14: Val Result: Acc: 0.8678, C_ACC: 0.7950, DOA: 7.8524, ACC_k: 0.9563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MT[4,6]-13: Val Result: Acc: 0.9076, C_ACC: 0.8227, DOA: 7.8645, ACC_k: 0.9557\n",
    "MT[4,6]-14: Val Result: Acc: 0.9240, C_ACC: 0.8152, DOA: 6.5563, ACC_k: 0.9727\n",
    "MT[4,6]-15: Val Result: Acc: 0.9253, C_ACC: 0.8220, DOA: 7.5267, ACC_k: 0.9669\n",
    "                        \n",
    "MT[3,7]-13: Val Result: Acc: 0.8920, C_ACC: 0.8188, DOA: 8.9324, ACC_k: 0.9430\n",
    "MT[3,7]-14: Val Result: Acc: 0.9218, C_ACC: 0.8205, DOA: 7.4889, ACC_k: 0.9600\n",
    "MT[3,7]-15: Val Result: Acc: 0.8787, C_ACC: 0.8222, DOA: 11.1863, ACC_k: 0.9215\n",
    "\n",
    "MT[3,7]123-13: Val Result: Acc: 0.9161, C_ACC: 0.8183, DOA: 7.7130, ACC_k: 0.9565\n",
    "MT[3,7]123-14: Val Result: Acc: 0.9283, C_ACC: 0.8204, DOA: 7.4296, ACC_k: 0.9630\n",
    "MT[3,7]123-15: Val Result: Acc: 0.9176, C_ACC: 0.8278, DOA: 7.0289, ACC_k: 0.9682\n",
    "                        \n",
    "MT[2,8]-13: Val Result: Acc: 0.8741, C_ACC: 0.8255, DOA: 9.8845, ACC_k: 0.9240\n",
    "MT[2,8]-14: Val Result: Acc: 0.9239, C_ACC: 0.8163, DOA: 7.6689, ACC_k: 0.9602\n",
    "MT[2,8]-15: Val Result: Acc: 0.9051, C_ACC: 0.8223, DOA: 8.0383, ACC_k: 0.9546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import models.KSL_base as KSL_base\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "def relu_fn(x):\n",
    "    \"\"\" Swish activation function \"\"\"\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Conv1dSamePadding(nn.Conv1d):\n",
    "    \"\"\" 1D Convolutions like TensorFlow \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        iw = x.size()[-1]\n",
    "        kw = self.weight.size()[-1]\n",
    "        sw = self.stride[-1]\n",
    "        #print(iw, sw, kw)\n",
    "        ow = math.ceil(iw / sw)\n",
    "        pad = max((ow - 1) * self.stride[0] + (kw - 1) * self.dilation[0] + 1 - iw, 0)\n",
    "        if pad > 0:\n",
    "            x = F.pad(x, [pad//2, pad - pad //2])\n",
    "        return F.conv1d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "    \n",
    "\n",
    "def drop_connect(inputs, p, training):\n",
    "    \"\"\" Drop connect. \"\"\"\n",
    "    if not training: return inputs\n",
    "    batch_size = inputs.shape[0]\n",
    "    keep_prob = 1 - p\n",
    "    random_tensor = keep_prob\n",
    "    #print(type(keep_prob), type(inputs))\n",
    "    random_tensor += torch.rand([batch_size, 1, 1], dtype=inputs.dtype)  # uniform [0,1)\n",
    "    binary_tensor = torch.floor(random_tensor).cuda()\n",
    "    output = inputs / keep_prob * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class MBConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Mobile Inverted Residual Bottleneck Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride, expand_ratio, input_filters, output_filters, se_ratio, drop_n_add):\n",
    "        super().__init__()\n",
    "        \n",
    "        self._bn_mom = 0.1\n",
    "        self._bn_eps = 1e-03\n",
    "        self.has_se = (se_ratio is not None) and (0 < se_ratio <= 1)\n",
    "        self.expand_ratio = expand_ratio\n",
    "        self.drop_n_add = drop_n_add\n",
    "\n",
    "        # Filter Expansion phase\n",
    "        inp = input_filters  # number of input channels\n",
    "        oup = input_filters * expand_ratio  # number of output channels\n",
    "        if expand_ratio != 1: # add it except at first block \n",
    "            self._expand_conv = Conv1dSamePadding(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
    "            self._bn0 = nn.BatchNorm1d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Depthwise convolution phase\n",
    "        k = kernel_size\n",
    "        s = stride\n",
    "        self._depthwise_conv = Conv1dSamePadding(\n",
    "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise(conv filter by filter)\n",
    "            kernel_size=k, stride=s, bias=False)\n",
    "        self._bn1 = nn.BatchNorm1d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "\n",
    "        # Squeeze and Excitation layer, if desired\n",
    "        if self.has_se:\n",
    "            num_squeezed_channels = max(1,int(input_filters * se_ratio))  # input channel * 0.25 ex) block2 => 16 * 0.25 = 4\n",
    "            self._se_reduce = Conv1dSamePadding(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
    "            self._se_expand = Conv1dSamePadding(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
    "\n",
    "        # Output phase\n",
    "        final_oup = output_filters\n",
    "        self._project_conv = Conv1dSamePadding(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
    "        self._bn2 = nn.BatchNorm1d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
    "    \n",
    "    def forward(self, inputs, drop_connect_rate=0.2):\n",
    "    \n",
    "        # Expansion and Depthwise Convolution\n",
    "        x = inputs\n",
    "        if self.expand_ratio != 1:\n",
    "            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n",
    "        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n",
    "\n",
    "        # Squeeze and Excitation\n",
    "        if self.has_se:\n",
    "            x_squeezed = F.adaptive_avg_pool1d(x, 1)\n",
    "            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n",
    "            x = torch.sigmoid(x_squeezed) * x\n",
    "            \n",
    "        # Output phase\n",
    "        x = self._bn2(self._project_conv(x))\n",
    "\n",
    "        # Skip connection and drop connect\n",
    "        if self.drop_n_add == True:\n",
    "            if drop_connect_rate:\n",
    "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
    "            x = x + inputs  # skip connection\n",
    "        return x\n",
    "\n",
    "class testNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 0.1\n",
    "        bn_eps = 1e-03\n",
    "\n",
    "        # stem\n",
    "        in_channels = 6\n",
    "        out_channels = 32\n",
    "        self._conv_stem = Conv1dSamePadding(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm1d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([]) # list 형태로 model 구성할 때\n",
    "        # stage2 r1_k3_s11_e1_i32_o16_se0.25\n",
    "        self._blocks.append(MBConvBlock(kernel_size=3, stride=1, expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, drop_n_add=False))\n",
    "        self._blocks.append(MBConvBlock(3, 2, 6, 16, 24, 0.25, False))\n",
    "        #self._blocks.append(MBConvBlock(3, 1, 6, 24, 24, 0.25, True))\n",
    "        # stage3 r2_k3_s22_e6_i16_o24_se0.25\n",
    "        \n",
    "        \n",
    "        self._blocks_ssl = nn.ModuleList([])\n",
    "        self._blocks_kws = nn.ModuleList([])\n",
    "        \n",
    "        #self._blocks_ssl.append(MBConvBlock(3, 2, 6, 16, 24, 0.25, False))\n",
    "        self._blocks_ssl.append(MBConvBlock(3, 1, 6, 24, 24, 0.25, True))\n",
    "        self._blocks_ssl.append(MBConvBlock(3, 2, 6, 24, 40, 0.25, False))\n",
    "        self._blocks_ssl.append(MBConvBlock(3, 1, 6, 40, 40, 0.25, True))\n",
    "        self._blocks_ssl.append(MBConvBlock(3, 2, 6, 40, 80, 0.25, False))\n",
    "        self._blocks_ssl.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
    "        self._blocks_ssl.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
    "        \n",
    "        #self._blocks_kws.append(MBConvBlock(3, 2, 6, 16, 24, 0.25, False))\n",
    "        self._blocks_kws.append(MBConvBlock(3, 1, 6, 24, 24, 0.25, True))\n",
    "        self._blocks_kws.append(MBConvBlock(3, 2, 6, 24, 40, 0.25, False))\n",
    "        self._blocks_kws.append(MBConvBlock(3, 1, 6, 40, 40, 0.25, True))\n",
    "        self._blocks_kws.append(MBConvBlock(3, 2, 6, 40, 80, 0.25, False))\n",
    "        self._blocks_kws.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
    "        self._blocks_kws.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
    "        \n",
    "        \n",
    "        # Head \n",
    "        in_channels = 80\n",
    "        out_channels = 112\n",
    "        self._conv_head_ssl = Conv1dSamePadding(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1_ssl = nn.BatchNorm1d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "        \n",
    "        self._conv_head_kws = Conv1dSamePadding(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1_kws = nn.BatchNorm1d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        self._dropout = 0.2\n",
    "        self._num_classes = 12\n",
    "        self._localizer = nn.Linear(out_channels, self._num_classes)\n",
    "        self._spotter = nn.Linear(out_channels, 1)\n",
    "  \n",
    "\n",
    "    def extract_features(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):          \n",
    "            x = block(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def ssl_features(self, x):\n",
    "        for idx, block in enumerate(self._blocks_ssl):          \n",
    "            x = block(x)\n",
    "        return x\n",
    "    \n",
    "    def kws_features(self, x):\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks_kws):          \n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "\n",
    "        # Convolution layers\n",
    "        x = self.extract_features(inputs)\n",
    "\n",
    "        x_ssl = self.ssl_features(x)\n",
    "        x_kws = self.kws_features(x)\n",
    "        \n",
    "        # Head\n",
    "        x_ssl = relu_fn(self._bn1_ssl(self._conv_head_ssl(x_ssl)))\n",
    "        x_ssl = F.adaptive_max_pool1d(x_ssl, 1).squeeze(-1)\n",
    "        \n",
    "        x_kws = relu_fn(self._bn1_kws(self._conv_head_kws(x_kws)))\n",
    "        x_kws = F.adaptive_max_pool1d(x_kws, 1).squeeze(-1)\n",
    "\n",
    "        if self._dropout:\n",
    "            x_ssl = F.dropout(x_ssl, p=self._dropout, training=self.training)\n",
    "            x_kws = F.dropout(x_kws, p=self._dropout, training=self.training)\n",
    "\n",
    "        x_local= self._localizer(x_ssl).view(-1, 2, 6)\n",
    "        x_kws = self._spotter(x_kws)\n",
    "        \n",
    "        return x_local[:, 0, :], x_local[:, 1, :], x_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.7",
   "language": "python",
   "name": "torch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
